{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bf960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_ta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe4e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nifty 50 Stocks\n",
    "\n",
    "df_stocks = pd.read_csv(\"https://archives.nseindia.com/content/indices/ind_nifty50list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a56da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Start Date and End Date for fetching data from yahooFinance.com.\n",
    "\n",
    "today  = date.today()\n",
    "enddate = time.mktime(today.timetuple())\n",
    "enddate = str(int(enddate))\n",
    "\n",
    "\n",
    "startdate = datetime.now().date().replace(year=2019, month=2, day=17)\n",
    "stdate=time.mktime(startdate.timetuple())\n",
    "stdate=str(int(stdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1ceeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock to predict\n",
    "\n",
    "stock = 'ADANIENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e34a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for historical data \n",
    "\n",
    "url = \"https://query1.finance.yahoo.com/v7/finance/download/\" +stock+ \".NS?period1=\" + stdate+ \"&period2=\" + enddate+ \"&interval=1d&events=history&includeAdjustedClose=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da54452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18382da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>118.300003</td>\n",
       "      <td>119.900002</td>\n",
       "      <td>116.099998</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>116.166290</td>\n",
       "      <td>2569451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>118.400002</td>\n",
       "      <td>119.800003</td>\n",
       "      <td>116.800003</td>\n",
       "      <td>118.250000</td>\n",
       "      <td>116.907784</td>\n",
       "      <td>2644152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-20</td>\n",
       "      <td>117.949997</td>\n",
       "      <td>121.099998</td>\n",
       "      <td>116.199997</td>\n",
       "      <td>120.050003</td>\n",
       "      <td>118.687355</td>\n",
       "      <td>3739081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>119.800003</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>117.900002</td>\n",
       "      <td>119.400002</td>\n",
       "      <td>118.044731</td>\n",
       "      <td>2698192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>120.250000</td>\n",
       "      <td>130.699997</td>\n",
       "      <td>119.800003</td>\n",
       "      <td>128.050003</td>\n",
       "      <td>126.596550</td>\n",
       "      <td>14695085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>1921.699951</td>\n",
       "      <td>1662.250000</td>\n",
       "      <td>1717.650024</td>\n",
       "      <td>1717.650024</td>\n",
       "      <td>12210940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>1889.000000</td>\n",
       "      <td>1611.349976</td>\n",
       "      <td>1749.699951</td>\n",
       "      <td>1749.699951</td>\n",
       "      <td>14579030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>1780.000000</td>\n",
       "      <td>1824.400024</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1779.099976</td>\n",
       "      <td>1779.099976</td>\n",
       "      <td>7636578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>1820.000000</td>\n",
       "      <td>1874.949951</td>\n",
       "      <td>1790.000000</td>\n",
       "      <td>1796.599976</td>\n",
       "      <td>1796.599976</td>\n",
       "      <td>5578515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1815.849976</td>\n",
       "      <td>1703.199951</td>\n",
       "      <td>1722.699951</td>\n",
       "      <td>1722.699951</td>\n",
       "      <td>5392513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Open         High          Low        Close  \\\n",
       "0    2019-02-18   118.300003   119.900002   116.099998   117.500000   \n",
       "1    2019-02-19   118.400002   119.800003   116.800003   118.250000   \n",
       "2    2019-02-20   117.949997   121.099998   116.199997   120.050003   \n",
       "3    2019-02-21   119.800003   121.000000   117.900002   119.400002   \n",
       "4    2019-02-22   120.250000   130.699997   119.800003   128.050003   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "986  2023-02-13  1850.000000  1921.699951  1662.250000  1717.650024   \n",
       "987  2023-02-14  1735.000000  1889.000000  1611.349976  1749.699951   \n",
       "988  2023-02-15  1780.000000  1824.400024  1750.000000  1779.099976   \n",
       "989  2023-02-16  1820.000000  1874.949951  1790.000000  1796.599976   \n",
       "990  2023-02-17  1800.000000  1815.849976  1703.199951  1722.699951   \n",
       "\n",
       "       Adj Close    Volume  \n",
       "0     116.166290   2569451  \n",
       "1     116.907784   2644152  \n",
       "2     118.687355   3739081  \n",
       "3     118.044731   2698192  \n",
       "4     126.596550  14695085  \n",
       "..           ...       ...  \n",
       "986  1717.650024  12210940  \n",
       "987  1749.699951  14579030  \n",
       "988  1779.099976   7636578  \n",
       "989  1796.599976   5578515  \n",
       "990  1722.699951   5392513  \n",
       "\n",
       "[991 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3eff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94d4c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Adj Close    float64\n",
       "Volume         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56bc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date data type (object --> datetime)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb2cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 991 entries, 0 to 990\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       991 non-null    datetime64[ns]\n",
      " 1   Open       991 non-null    float64       \n",
      " 2   High       991 non-null    float64       \n",
      " 3   Low        991 non-null    float64       \n",
      " 4   Close      991 non-null    float64       \n",
      " 5   Adj Close  991 non-null    float64       \n",
      " 6   Volume     991 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 54.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d548c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting date column as index\n",
    "\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb960380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21',\n",
       "               '2019-02-22', '2019-02-25', '2019-02-26', '2019-02-27',\n",
       "               '2019-02-28', '2019-03-01',\n",
       "               ...\n",
       "               '2023-02-06', '2023-02-07', '2023-02-08', '2023-02-09',\n",
       "               '2023-02-10', '2023-02-13', '2023-02-14', '2023-02-15',\n",
       "               '2023-02-16', '2023-02-17'],\n",
       "              dtype='datetime64[ns]', name='Date', length=991, freq=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e06df7",
   "metadata": {},
   "source": [
    "# LSTM MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b8f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d08421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MinMax = MinMaxScaler()\n",
    "df1 = MinMax.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15820397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test\n",
    "\n",
    "training_size = int(len(df1)*0.70)\n",
    "test_size = len(df1)-training_size \n",
    "train_data = df1[0:training_size,:]\n",
    "test_data = df1[training_size :len(df1), :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5342e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an array of values into dataset matrix\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    X,Y = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]   \n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8488172",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = create_dataset(train_data, 100)\n",
    "X_test, Y_test = create_dataset(test_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47418af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5991dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33019400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c6da7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 50)           10400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 50)           20200     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "192814bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 21s 601ms/step - loss: 0.0166 - val_loss: 0.0334\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.0019 - val_loss: 0.0469\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 8.2872e-04 - val_loss: 0.0111\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 3s 289ms/step - loss: 4.6933e-04 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 3.2259e-04 - val_loss: 0.0106\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 2.6520e-04 - val_loss: 0.0122\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 2.4932e-04 - val_loss: 0.0122\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 2.3331e-04 - val_loss: 0.0129\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 2.2919e-04 - val_loss: 0.0140\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 2.1688e-04 - val_loss: 0.0158\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 2s 251ms/step - loss: 2.3092e-04 - val_loss: 0.0167\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 2.3072e-04 - val_loss: 0.0227\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 2.1815e-04 - val_loss: 0.0248\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 2.3584e-04 - val_loss: 0.0226\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 2.1769e-04 - val_loss: 0.0203\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 2s 253ms/step - loss: 1.9530e-04 - val_loss: 0.0234\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 1.8910e-04 - val_loss: 0.0248\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 1.8351e-04 - val_loss: 0.0264\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 1.8139e-04 - val_loss: 0.0302\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 1.8775e-04 - val_loss: 0.0255\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 1.7846e-04 - val_loss: 0.0307\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 1.8564e-04 - val_loss: 0.0265\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 2.0012e-04 - val_loss: 0.0322\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 1.8603e-04 - val_loss: 0.0330\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 1.8651e-04 - val_loss: 0.0273\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 2.1956e-04 - val_loss: 0.0315\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 1.8002e-04 - val_loss: 0.0312\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 1.8628e-04 - val_loss: 0.0338\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 1.7766e-04 - val_loss: 0.0300\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 1.7958e-04 - val_loss: 0.0315\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 1.6847e-04 - val_loss: 0.0371\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 1.8412e-04 - val_loss: 0.0355\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 1.8981e-04 - val_loss: 0.0314\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 1.9179e-04 - val_loss: 0.0242\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 2.7346e-04 - val_loss: 0.0243\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 2.7061e-04 - val_loss: 0.0305\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 2.0198e-04 - val_loss: 0.0360\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 1.8016e-04 - val_loss: 0.0354\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.6650e-04 - val_loss: 0.0296\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 2.0336e-04 - val_loss: 0.0376\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 1.9869e-04 - val_loss: 0.0369\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 3s 251ms/step - loss: 1.9571e-04 - val_loss: 0.0363\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 1.9424e-04 - val_loss: 0.0376\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 1.8546e-04 - val_loss: 0.0294\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 1.9471e-04 - val_loss: 0.0354\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.6768e-04 - val_loss: 0.0281\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 1.9676e-04 - val_loss: 0.0205\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 2.6505e-04 - val_loss: 0.0277\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 2.0655e-04 - val_loss: 0.0281\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.6730e-04 - val_loss: 0.0271\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.7716e-04 - val_loss: 0.0265\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.9625e-04 - val_loss: 0.0254\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.8397e-04 - val_loss: 0.0282\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 1.7948e-04 - val_loss: 0.0286\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 3s 252ms/step - loss: 1.8597e-04 - val_loss: 0.0296\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.6527e-04 - val_loss: 0.0320\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 1.6013e-04 - val_loss: 0.0291\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 3s 264ms/step - loss: 1.6082e-04 - val_loss: 0.0310\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.5913e-04 - val_loss: 0.0316\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.6330e-04 - val_loss: 0.0291\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 1.5311e-04 - val_loss: 0.0264\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 1.6722e-04 - val_loss: 0.0276\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 1.6460e-04 - val_loss: 0.0296\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.5393e-04 - val_loss: 0.0294\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.5393e-04 - val_loss: 0.0303\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 1.4780e-04 - val_loss: 0.0287\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 1.5228e-04 - val_loss: 0.0317\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.5626e-04 - val_loss: 0.0274\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.5588e-04 - val_loss: 0.0278\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.7434e-04 - val_loss: 0.0238\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.5931e-04 - val_loss: 0.0239\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.6567e-04 - val_loss: 0.0272\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 1.5622e-04 - val_loss: 0.0242\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.7795e-04 - val_loss: 0.0279\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.4847e-04 - val_loss: 0.0289\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.5277e-04 - val_loss: 0.0276\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.4541e-04 - val_loss: 0.0278\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 249ms/step - loss: 1.4846e-04 - val_loss: 0.0275\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.7193e-04 - val_loss: 0.0282\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 1.5295e-04 - val_loss: 0.0296\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 2s 243ms/step - loss: 1.5203e-04 - val_loss: 0.0239\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 1.8959e-04 - val_loss: 0.0210\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 2.0421e-04 - val_loss: 0.0290\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 2.1227e-04 - val_loss: 0.0273\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.5860e-04 - val_loss: 0.0294\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 2s 248ms/step - loss: 1.7092e-04 - val_loss: 0.0344\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 1.8426e-04 - val_loss: 0.0296\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 1.4719e-04 - val_loss: 0.0270\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 1.3533e-04 - val_loss: 0.0296\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 1.4003e-04 - val_loss: 0.0272\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 1.3124e-04 - val_loss: 0.0303\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.4874e-04 - val_loss: 0.0271\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 2s 250ms/step - loss: 1.3535e-04 - val_loss: 0.0255\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 3s 261ms/step - loss: 1.5328e-04 - val_loss: 0.0243\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 1.2638e-04 - val_loss: 0.0265\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 1.2567e-04 - val_loss: 0.0276\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.2689e-04 - val_loss: 0.0242\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 1.2152e-04 - val_loss: 0.0298\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 2s 252ms/step - loss: 1.3624e-04 - val_loss: 0.0210\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 3s 260ms/step - loss: 1.8038e-04 - val_loss: 0.0215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291619c3970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86ef64dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 5s 58ms/step\n",
      "7/7 [==============================] - 0s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d3c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=MinMax.inverse_transform(train_predict)\n",
    "test_predict=MinMax.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02557b38",
   "metadata": {},
   "source": [
    "# Validating the Fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ba0908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13162a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868.5210528775762"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data RMSE\n",
    "\n",
    "np.sqrt(mean_squared_error(Y_train,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "521bebee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2604.5006780196027"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data RMSE\n",
    "\n",
    "np.sqrt(mean_squared_error(Y_test,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23cfd6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754328.8192915735"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data MSE\n",
    "\n",
    "mean_squared_error(Y_train,train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc042df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6783423.781804571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data MSE\n",
    "\n",
    "mean_squared_error(Y_test,test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ae7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
